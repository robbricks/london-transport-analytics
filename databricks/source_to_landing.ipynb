{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7b39e37a-8528-4590-9e41-9cbf8d5c26fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pyspark.sql.functions import from_json, expr, lit\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b87ceb7c-68f1-4456-a7c6-24809d1d0295",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "**Create a Secret Scope and Secret**\n",
    "\n",
    "`\n",
    "databricks secrets create-scope tfl_analytics_scope\n",
    "`\n",
    "\n",
    "`\n",
    "databricks secrets put-secret --json '{\n",
    "  \"scope\": \"tfl_analytics_scope\",\n",
    "  \"key\": \"tfl_app_key\",\n",
    "  \"string_value\": \"xxx\"\n",
    "}'\n",
    "`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edc10dd9-75c3-4e42-9763-7552562c73a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tfl_app_key = dbutils.secrets.get(scope = \"tfl_analytics_scope\", key = \"tfl_app_key\")\n",
    "api_name = \"BikePoint\"\n",
    "directory_name = \"bike_point\"\n",
    "url = f\"https://api.tfl.gov.uk/{api_name}/?app_key={tfl_app_key}\"\n",
    "catalog_name = \"robin_huebner\"\n",
    "schema_name= \"tfl_analytics\"\n",
    "volume_name = \"landing\"\n",
    "execution_timestamp = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1c212782-ca53-4afd-98a1-989a823cfd66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(execution_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf6620ca-33d2-48d0-8316-eaececde3423",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# spark.sql(f\"CREATE CATALOG IF NOT EXISTS {catalog_name}\")\n",
    "spark.sql(f\"USE CATALOG {catalog_name}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {catalog_name}.{schema_name}\")\n",
    "spark.sql(f\"USE SCHEMA {schema_name}\")\n",
    "spark.sql(f\"CREATE VOLUME IF NOT EXISTS {catalog_name}.{schema_name}.{volume_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "74c8b362-9d6d-42e1-9e22-7029769063e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "data = response.json()\n",
    "\n",
    "dbutils.fs.put(f\"/Volumes/{catalog_name}/{schema_name}/{volume_name}/{directory_name}/{execution_timestamp}_tfl_{schema_name}.json\", json.dumps(data), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24050240-f65c-479f-9a30-83cd68ba4fea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  sequence(DATE '2025-01-01', DATE '2026-12-31', INTERVAL 1 DAY) as calendar_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "735f6a1a-97a1-43e5-99ee-004f9704b177",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT\n",
    "  explode(sequence(DATE '2025-01-01', DATE '2026-12-31', INTERVAL 1 DAY)) as calendar_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56372d7e-aed8-47d4-9b93-2bc957be191e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import explode, sequence, to_date, lit\n",
    "# Create a DataFrame with a sequence of dates\n",
    "date_df = spark.createDataFrame([1], \"int\").select(\n",
    "    explode(sequence(to_date(lit(\"2023-01-01\")), to_date(lit(\"2023-01-31\")), lit(\"interval 1 day\"))).alias(\"date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "465e0b0f-b62f-4d21-8798-aca155eacf95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(date_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3926807839376893,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 2
   },
   "notebookName": "source_to_landing",
   "widgets": {
    "app_key": {
     "currentValue": "",
     "nuid": "aa3b2944-9718-4d73-bec8-e0e2c3960612",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "app_key",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "app_key",
      "options": {
       "widgetType": "text",
       "autoCreated": false,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
