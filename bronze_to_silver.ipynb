{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "817ab780-2ff1-486b-8a7e-73c0684a2c63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "import json\n",
    "from pyspark.sql.functions import from_json, expr, lit, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, ArrayType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51a7a644-c94b-4b00-8e99-c8fffbfb878d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "catalog_name = \"robin_huebner\"\n",
    "schema_name= \"tfl_analytics\"\n",
    "volume_name = \"bronze\"\n",
    "directory_name = \"bike_point\"\n",
    "\n",
    "source_volume = f\"/Volumes/{catalog_name}/{schema_name}/{volume_name}/{directory_name}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "40f680d1-3581-40cf-bc78-17d0ebc8cb63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "  comment=\"Loads JSON files from bronze into silver table\"\n",
    ")\n",
    "def silver_bike_point():\n",
    "  df = (spark.readStream\n",
    "        .format(\"cloudFiles\")\n",
    "        .option(\"cloudFiles.format\", \"json\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .load(source_volume)\n",
    "  )\n",
    "\n",
    "  additional_properties_schema = ArrayType(\n",
    "      StructType([\n",
    "          StructField(\"key\", StringType(), True),\n",
    "          StructField(\"value\", StringType(), True)\n",
    "      ])\n",
    "  )\n",
    "\n",
    "  df = df.withColumn(\n",
    "    \"additionalProperties\",\n",
    "    from_json(col(\"additionalProperties\"), additional_properties_schema)\n",
    "  )\n",
    "\n",
    "  # Define fields to extract from JSON\n",
    "  fields_to_extract = [\n",
    "      \"TerminalName\",\n",
    "      \"Installed\",\n",
    "      \"Locked\",\n",
    "      \"InstallDate\",\n",
    "      \"RemovalDate\",\n",
    "      \"Temporary\",\n",
    "      \"NbBikes\",\n",
    "      \"NbEmptyDocks\",\n",
    "      \"NbDocks\",\n",
    "      \"NbStandardBikes\",\n",
    "      \"NbEBikes\"\n",
    "  ]\n",
    "\n",
    "  # Define expressions for extraction from JSON\n",
    "  expressions_extract = [\n",
    "    f\"filter(additionalProperties, x -> x.key = '{field}')[0].value as {field}\"\n",
    "    for field in fields_to_extract\n",
    "  ]\n",
    "\n",
    "  # Extract specified fields from JSON\n",
    "  df = df.selectExpr(\"*\", *expressions_extract)\n",
    "\n",
    "  # Map each field to a Spark expression\n",
    "  for field in fields_to_extract:\n",
    "    df = df.withColumn(\n",
    "        field,\n",
    "        expr(f\"filter(additionalProperties, x -> x.key = '{field}')[0].value as {field}\")\n",
    "    )\n",
    "\n",
    "\n",
    "  # Define columns to keep and column names\n",
    "  fields_to_rename = {\n",
    "    \"id\": \"bikepoint_id\",\n",
    "    \"commonName\": \"bikepoint_name\",\n",
    "    \"lat\": \"bikepoint_latitude\",\n",
    "    \"lon\": \"bikepoint_longitude\",\n",
    "    \"TerminalName\": \"terminal_name\",\n",
    "    \"Installed\": \"installed\",\n",
    "    \"Locked\": \"locked\",\n",
    "    \"InstallDate\": \"install_date\",\n",
    "    \"RemovalDate\": \"removal_date\",\n",
    "    \"Temporary\": \"temporary\",\n",
    "    \"NbBikes\": \"bike_count\",\n",
    "    \"NbEmptyDocks\": \"empty_dock_count\",\n",
    "    \"NbDocks\": \"dock_count\",\n",
    "    \"NbStandardBikes\": \"standard_bike_count\",\n",
    "    \"NbEBikes\": \"ebike_count\",\n",
    "  }\n",
    "\n",
    "  # Define expression to filter and rename columns\n",
    "  expressions_rename = [\n",
    "    f\"{old_name} as {new_name}\"\n",
    "    for old_name, new_name in fields_to_rename.items()\n",
    "  ]\n",
    "\n",
    "  # Filter and rename dataframe\n",
    "  df = df.selectExpr(\n",
    "    [*expressions_rename]\n",
    "  )\n",
    "\n",
    "  # Add audit information to the table\n",
    "  df = (\n",
    "    df.withColumn(\"source_system\", lit(\"TFL\"))\n",
    "    .withColumn(\"ingestion_user\", expr(\"CURRENT_USER()\"))\n",
    "    .withColumn(\"ingestion_timestamp\", expr(\"CURRENT_TIMESTAMP()\"))\n",
    "  )\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "691fab80-237a-4d28-a935-d1a03f317bec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # Load dataframe from volume\n",
    "# df = spark.read.json(\"/Volumes/robin_huebner/tfl_analytics/bronze/bike_point/tfl_data.json\")\n",
    "\n",
    "# # Define fields to extract from JSON\n",
    "# fields_to_extract = [\n",
    "#     \"TerminalName\",\n",
    "#     \"Installed\",\n",
    "#     \"Locked\",\n",
    "#     \"InstallDate\",\n",
    "#     \"RemovalDate\",\n",
    "#     \"Temporary\",\n",
    "#     \"NbBikes\",\n",
    "#     \"NbEmptyDocks\",\n",
    "#     \"NbDocks\",\n",
    "#     \"NbStandardBikes\",\n",
    "#     \"NbEBikes\"\n",
    "# ]\n",
    "\n",
    "# # Define expressions for extraction from JSON\n",
    "# expressions_extract = [\n",
    "#   f\"filter(additionalProperties, x -> x.key = '{field}')[0].value as {field}\"\n",
    "#   for field in fields_to_extract\n",
    "# ]\n",
    "\n",
    "# # Extract specified fields from JSON\n",
    "# df = df.selectExpr(\"*\", *expressions_extract)\n",
    "\n",
    "# # Define columns to keep and column names\n",
    "# fields_to_rename = {\n",
    "#   \"id\": \"bikepoint_id\",\n",
    "#   \"commonName\": \"bikepoint_name\",\n",
    "#   \"lat\": \"bikepoint_latitude\",\n",
    "#   \"lon\": \"bikepoint_longitude\",\n",
    "#   \"TerminalName\": \"terminal_name\",\n",
    "#   \"Installed\": \"installed\",\n",
    "#   \"Locked\": \"locked\",\n",
    "#   \"InstallDate\": \"install_date\",\n",
    "#   \"RemovalDate\": \"removal_date\",\n",
    "#   \"Temporary\": \"temporary\",\n",
    "#   \"NbBikes\": \"bike_count\",\n",
    "#   \"NbEmptyDocks\": \"empty_dock_count\",\n",
    "#   \"NbDocks\": \"dock_count\",\n",
    "#   \"NbStandardBikes\": \"standard_bike_count\",\n",
    "#   \"NbEBikes\": \"ebike_count\",\n",
    "# }\n",
    "\n",
    "# # Define expression to filter and rename columns\n",
    "# expressions_rename = [\n",
    "#   f\"{old_name} as {new_name}\"\n",
    "#   for old_name, new_name in fields_to_rename.items()\n",
    "# ]\n",
    "\n",
    "# # Filter and rename dataframe\n",
    "# df = df.selectExpr(\n",
    "#   [*expressions_rename]\n",
    "# )\n",
    "\n",
    "# # Add audit information to the table\n",
    "# df = (\n",
    "#   df.withColumn(\"source_system\", lit(\"TFL\"))\n",
    "#   .withColumn(\"ingestion_user\", expr(\"CURRENT_USER()\"))\n",
    "#   .withColumn(\"ingestion_timestamp\", expr(\"CURRENT_TIMESTAMP()\"))\n",
    "# )\n",
    "\n",
    "# # Write dataframe to silver\n",
    "# df.write.mode(\"append\").saveAsTable(\"silver_tfl_bike_point\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "75ac9525-9c1f-43d6-ab95-3e41609950df",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "bronze_to_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
